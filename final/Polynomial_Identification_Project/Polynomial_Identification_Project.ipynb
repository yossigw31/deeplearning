{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitted by:\n",
    " \n",
    "* Name 1: \n",
    "* Name 2:\n",
    "\n",
    "## To be submitted by: 15.3.2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomials Identification Project\n",
    "\n",
    "This project identifies poynomials given in images. Specifically, polynomials of rank 3 are provided as RGB images to a neural netork, whose outputs are the coefficients of the given polynomials. The domain considered is \"[0,1]x[0,1] box\". PyTorch is the platform used.\n",
    "\n",
    "### **You are given the following files:**\n",
    "  Three directories named \"train\", \"validation\", and \"test\" each containing the following:\n",
    "  1. a directory called \"images\" with RGB png files of size 128x128 (so image that is read has shape (3,128,128))\n",
    "  2. a file \"labels.txt\" containing the coefficients of all images in \"images\" directory\n",
    "\n",
    "Since this problem is a somewhat open ended, you are given a suggested structure and some functionality that is already implemented for you (see below). You are not at all obigated to follow this structure or use the code given. \n",
    "\n",
    "**Notes:** \n",
    "- When referring to a \"polynomial\", we either refer to an image or to the 4 coefficients. The meaning should be clear from context  \n",
    "- \"network\" and \"model\" are used interchangeably throughout this documentation.\n",
    " \n",
    " \n",
    "### **General structure (in order):**\n",
    " 1. DataSet and DataLoader            - this is how you load data into the network **(given to you)**\n",
    " 2. Seperable convolution class       - You can use this in your network class if you want **(given to you)**\n",
    " 3. Neural Network definition         - the class that defines your model   **(NEED TO IMPLEMENT)**\n",
    " 4. calculate model parameters number - useful to get a feel for network's size **(given to you)**\n",
    " 5. estimate number of ops per forward feed - the bigger this is the slower the training **(given to you)**\n",
    " 6. loss function definition          - to be used in training **(NEED TO IMPLEMENT)**\n",
    " 7. create an optimizer               - choose your optimizer **(NEED TO IMPLEMENT)**\n",
    " 8. estimate ops per forward feed     - use function given to you to estimate this **(implement for convenience)**\n",
    " 9. view images and coefficients      - example code to help you see how to use loaders **(given to you)**\n",
    " 10. validate_model                   - returns avg loss per image for a model and loader  **(NEED TO IMPLEMENT)**\n",
    " 11. train_model                      - trains the network **(NEED TO IMPLEMENT)**\n",
    " 12. plot train/validaion losses      - visualizing train and validation losses from training **(given to you)**\n",
    " 13. save/load model                  - allows you to save and load model to disk for later use **(given to you)**\n",
    " 14. visualizing polynomials          - overlaying net polynomials over actual polynomials **(given to you)**\n",
    " \n",
    " \n",
    "### ** What you need to do **\n",
    "You have 5 (and a half...) things to do:\n",
    " 1. Create a PolyNet class, which is your network model. This is a key component. The output of your model should be 4 numbers that represent the coefficients of the input polynomial image fed into your network. You should keep in mind the number of parameters in your model. If there are too many, it may overfit (and take longer to run). If there are too few, it may not be able to learn the task needed. A typical structure would have convolutional layers first and fully connected at the end, thus reducing number of parameteres. Consider which activation function you want to use, and whether or not you wish to use batch normalization or dropout. Also, you may use seperable convolution or regular convolution or both. Maxpool layers are also possible. Be creative.\n",
    " \n",
    " 2. Create a loss function. This is another key component as it defines what it means for two polynomials to be similar or not. Namely, two polynomials (represented by two sets of coefficients: ground truth (\"labels\") and network outputs (\"outputs\")), whose images look similar should have a smaller loss than two polynomials whose images look less simialr. Think about how you would quantify \"closeness\"/\"similarity\" of polynomials.\n",
    "\n",
    " 3. Choose an optimizer. Look here for some ideas: https://pytorch.org/docs/master/optim.html\n",
    " \n",
    " 4. (This is the \"half\" thing to do). For your conveinece you may want to use the function calc_ops() that is given to you to calculate an estimate of the number of operations that your network does per feed forward. To do this, you need to enter your own network structure. An example of an arbitrary network is privided to you.\n",
    " \n",
    " 5. Create a validate_model function that assesses (tests) the performance of a model. It returns the average loss per image for a given loader. It can be run on any set of data (train, validation, or test). You may want to run this function on validation set (loader) from within the train function (see below) after each epoch so as to see how loss behaves on validation during the training process.\n",
    " \n",
    " 6. Create a train_model function that trains model. This function updates the following parameteres: model, train_losses, and validation_losses. Model is updated simply by the training processes when optimzer.step() is called. The other two parameteres are lists that hold the average loss per image for the corresponding data (train or validation). After every epoch (i.e., iteration that goes over the entire train data), you should save into these lists the average loss per image for the corresponding data loader. These lists are useful in that you can plot them (functionality given to you) and observe how model behaves. Observe: this fucnton returs nothing, however, it updates parameteres by reference. Specifically, model is updated (trained), and so are train and validation losses values.\n",
    " \n",
    "**Note:** You are given three sets of data: trian, validation, and test. It is recommended that test not be touched until the very end, and validation be used to get a sense of your network's performance. \n",
    "\n",
    "### ** Running on a GPU: **\n",
    "It is not necessary to use a GPU for this project. However, if you choose to do so, you will gain a major speedup to your training, which will save you much time. The code given to you identifies the hardware used and will  automatically run on either a GPU or CPU. \n",
    "\n",
    "### ** Useful links: **\n",
    "1. PyTorch master tutorial - VERY useful: https://pytorch.org/docs/master/nn.html\n",
    "2. PyTorch optimizers: https://pytorch.org/docs/master/optim.html\n",
    "3. A list of possible reasons why things go wrong: https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607#74de\n",
    "\n",
    "### ** Final tips: **\n",
    "Use the Internet! Things will not work first time. You will get strange error messages. Google them up. The web is  great resource for tackling problems ranging from python error messages, to things not doing what you'd like them to do.\n",
    "\n",
    "\n",
    "### ** Submission Instructions**\n",
    "The project is to be submittd in pairs. You need to submit the following three files:\n",
    "1. model.dat                            - This is your saved model \n",
    "2. Polynomial_Identifier_Project.ipynb  - This is this notebook containing all of your work\n",
    "3. model.py                             - A file containing your PolyNet class only. \n",
    "\n",
    "Before you submit, run \"check_before_submission.ipynb\" to make sure your model can be properly tested. See instructions for running this notebook inside.\n",
    "\n",
    "Make sure your names appear at the top of this notebook in the appropriate place.\n",
    "\n",
    "### **GOOD LUCK!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "from PIL import ImageDraw\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from scipy import integrate as integrate\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import uuid\n",
    "from torch.optim import lr_scheduler\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache() \n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class definition (given to you) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_dir):\n",
    "        \"\"\"\n",
    "        Initializing dataset by generating a dicitonary of labels, where an image file name is the key \n",
    "        and its labels are the contents of that entry in the dictionary. Images are not loaded. This way it\n",
    "        is possible to iterate over arbitrarily large datasets (limited by labels dicitonary fitting \n",
    "        in memory, which is not a problem in practice)\n",
    "        \n",
    "        Args:\n",
    "            dataset_dir : path to directory with images and labels. In this directory we expect to find\n",
    "                          a directory called \"images\" containing the input images, and a file called \n",
    "                          \"labels.txt\" containing desired labels (coefficients)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.labels_dict = self.gen_labels_dict()\n",
    "        self.images_keys = list(self.labels_dict)  # getting the keys of the dictionary as list\n",
    "        self.images_keys.sort()                    # sorting so as to have in alphabetical order \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_dict)\n",
    "\n",
    "    def __getitem__(self, index):    \n",
    "        \"\"\"\n",
    "        This funtion makes it possible to iterate over the PolyDataset\n",
    "        Args:\n",
    "            index: running index of images\n",
    "            \n",
    "        Returns:\n",
    "            sample: a dicitionary with three entries:\n",
    "                    1. 'image'  contains the image\n",
    "                    2. 'labels' contains labels (coeffs) corresponding to image\n",
    "                    3. 'fname'  contains name of file (image_key) - may be useful for debugging\n",
    "        \"\"\"\n",
    "        image_key = self.images_keys[index]     # recall - key is the file name of the corresponding image\n",
    "        image = np.array(Image.open(image_key)) # image has shape: (128, 128, 3)\n",
    "        image = image/255.0                     # simple normalization - just to maintain small numbers\n",
    "        image = np.transpose(image, (2, 0, 1))  # network needs RGB channels to be first index\n",
    "        labels = self.labels_dict[image_key]\n",
    "        sample = {'image': image, 'labels': labels, 'fname':image_key}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    def gen_labels_dict(self):\n",
    "        \"\"\"\n",
    "        This fucntion generates a dictionary of labels\n",
    "        \n",
    "        Returns:\n",
    "            labels_dict: the key is image file name and an array of labels is the corresponding contents \n",
    "        \"\"\"\n",
    "        \n",
    "        labels_fname = self.dataset_dir + \"/labels.txt\"\n",
    "        labels_dict = {}\n",
    "        with open(labels_fname, \"r\") as inp:\n",
    "            for line in inp:\n",
    "                line = line.split('\\n')[0]                                      # remove '\\n' from end of line \n",
    "                line = line.split(',')\n",
    "                key  = self.dataset_dir + '/images/' + line[0].strip() + \".png\" # image file name is the key\n",
    "                del line[0]\n",
    "                \n",
    "                list_from_line = [float(item) for item in line]\n",
    "                labels_dict[key] = np.asarray(list_from_line, dtype=np.float32)\n",
    "                        \n",
    "        return labels_dict             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Loaders (given to you) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader examples     : ~ 10\n",
      "validation loader examples: ~ 10\n",
      "test loader examples      : ~ 100\n"
     ]
    }
   ],
   "source": [
    "train_dir      = \"./clean_train_10/\"\n",
    "validation_dir = \"./clean_train_10/\"\n",
    "test_dir       = \"./test/\"\n",
    "\n",
    "\n",
    "train_dataset = PolyDataset(train_dir)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=2,\n",
    "                          shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "validation_dataset = PolyDataset(validation_dir)\n",
    "\n",
    "validation_loader = DataLoader(validation_dataset, \n",
    "                               batch_size=1,\n",
    "                               shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = PolyDataset(test_dir)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size=1,\n",
    "                          shuffle=False)\n",
    "import matplotlib.pyplot as plt \n",
    "conaiter =  iter(train_loader).next()\n",
    "#print(conaiter[\"image\"].shape)\n",
    "#print(conaiter[\"labels\"])\n",
    "\n",
    "print(\"train loader examples     : ~\", len(train_loader)*train_loader.batch_size)\n",
    "print(\"validation loader examples: ~\", len(validation_loader)*validation_loader.batch_size)\n",
    "print(\"test loader examples      : ~\", len(test_loader)*test_loader.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperable convolution class (given to you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Seperable convolution - you can try it out if you want\n",
    "    \"\"\"\n",
    "    def __init__(self,in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super(SeparableConv2d,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels,\n",
    "                               in_channels,\n",
    "                               kernel_size,\n",
    "                               stride,\n",
    "                               padding,\n",
    "                               dilation,\n",
    "                               groups=in_channels,\n",
    "                               bias=bias)\n",
    "        \n",
    "        self.pointwise = nn.Conv2d(in_channels, \n",
    "                                   out_channels, \n",
    "                                   kernel_size=1,\n",
    "                                   stride=1, \n",
    "                                   padding=0, \n",
    "                                   dilation=1, \n",
    "                                   groups=1, \n",
    "                                   bias=bias)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyNet(nn.Module):    # nn.Module is parent class\n",
    "    def __init__(self):\n",
    "        super(PolyNet, self).__init__()  # calls init of parent class\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_channels=3,\n",
    "                                              out_channels=30,\n",
    "                                              kernel_size=3,\n",
    "                                              stride=1),\n",
    "                                     nn.LeakyReLU(),\n",
    "                                     nn.BatchNorm2d(30))\n",
    "#         126\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(in_channels=30,\n",
    "                                              out_channels=15,\n",
    "                                              kernel_size=4,\n",
    "                                              stride=2),\n",
    "                                              nn.LeakyReLU(),\n",
    "                                              nn.BatchNorm2d(15))\n",
    "#      62   \n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(in_channels=15,\n",
    "                                              out_channels=15,\n",
    "                                              kernel_size=(62,2)),\n",
    "                                              nn.LeakyReLU(),\n",
    "                                              nn.BatchNorm2d(15))\n",
    "\n",
    "#         self.layer3 = nn.Sequential(nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(61*15, 300)\n",
    "        self.fc4 = nn.Linear(300, 4)\n",
    "        # ----------------------------------------------\n",
    "        # implementation needed here\n",
    "        # ----------------------------------------------\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.leaky_relu_(self.fc4(out))\n",
    "        \"\"\"\n",
    "        Feed forward through network\n",
    "        Args:\n",
    "            x - input to the network\n",
    "            \n",
    "        Returns \"out\", which is the network's output\n",
    "        \"\"\"\n",
    "\n",
    "        # ----------------------------------------------\n",
    "        # implementation needed here\n",
    "        # ----------------------------------------------\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=4, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet18():\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2]).to(device)\n",
    "   \n",
    "    return model\n",
    "\n",
    "def resnet101():\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3]).to(device)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get number of trainable parameters (given to you)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_params_num(model):\n",
    "    \"\"\"\n",
    "    This fucntion returns the number of trainable parameters of neural network model\n",
    "    You may want to call it after you create your model to see how many parameteres the model has\n",
    "    Args:\n",
    "        model - neural net to examine. NOTE: this is an instantiation of the PolyNet class, not the class itself \n",
    "    \"\"\"\n",
    "    \n",
    "    model_parameters = filter(lambda p: p.requires_grad==True, model.parameters())\n",
    "    params_num = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params_num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get an estimate number of operations (given to you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ops(inp_size, net_struct):\n",
    "    \"\"\"\n",
    "    Calculates a rough number of operations for a given network topology\n",
    "    Args:\n",
    "        inp_size - (W,H) of input \n",
    "        net_struct - list of tuples describing structure of network. \n",
    "        \n",
    "        Example:\n",
    "         (('conv2d', (3, 8, 3, 1, 0)),  # cin, cout, kernel, stride, pad\n",
    "          ('conv2d', (8, 8, 3, 1, 0)),\n",
    "          ('MaxPool2d', (2,2)),         # kernel, stride\n",
    "          ('fc', (64, 8)),      \n",
    "          ('fc', (8, 4)))\n",
    "         \n",
    "    \"\"\"\n",
    "    \n",
    "    ops = 0\n",
    "    W, H = inp_size\n",
    "    for curr_item in net_struct:\n",
    "        if curr_item[0] == 'conv2d':\n",
    "            cin = curr_item[1][0]\n",
    "            cout = curr_item[1][1]\n",
    "            kernel = curr_item[1][2]\n",
    "            stride = curr_item[1][3]\n",
    "            curr_ops = (W*H*cin*cout*kernel*kernel)/stride\n",
    "            pad = curr_item[1][4]\n",
    "            W = (W +2*pad - kernel)/stride + 1\n",
    "            H = (H +2*pad - kernel)/stride + 1\n",
    "            ops += curr_ops\n",
    "            print (curr_item, \":\",  \"{:,}\".format(int(curr_ops)))\n",
    "        elif curr_item[0] == 'MaxPool2d':\n",
    "            kernel = curr_item[1][0]\n",
    "            stride = curr_item[1][1]\n",
    "            W = (W - kernel)/stride + 1\n",
    "            H = (H - kernel)/stride + 1\n",
    "        else:\n",
    "            curr_ops = curr_item[1][0] * curr_item[1][1]\n",
    "            ops += curr_ops\n",
    "            print (curr_item, \":\",  \"{:,}\".format(int(curr_ops)))\n",
    "            \n",
    "    return int(ops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0204, 0.0408, 0.0612, 0.0816, 0.1020, 0.1224, 0.1429, 0.1633,\n",
      "        0.1837, 0.2041, 0.2245, 0.2449, 0.2653, 0.2857, 0.3061, 0.3265, 0.3469,\n",
      "        0.3673, 0.3878, 0.4082, 0.4286, 0.4490, 0.4694, 0.4898, 0.5102, 0.5306,\n",
      "        0.5510, 0.5714, 0.5918, 0.6122, 0.6327, 0.6531, 0.6735, 0.6939, 0.7143,\n",
      "        0.7347, 0.7551, 0.7755, 0.7959, 0.8163, 0.8367, 0.8571, 0.8776, 0.8980,\n",
      "        0.9184, 0.9388, 0.9592, 0.9796, 1.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computePoly(cordinates,x):\n",
    "    return cordinates[0] * torch.pow(x,3).to(device)  +  cordinates[1] * torch.pow(x,2).to(device) +  cordinates[2] * torch.pow(x,1).to(device) +  cordinates[3]\n",
    "\n",
    "def PolynomialLossNew(outputs, labels):\n",
    "    L2 = nn.MSELoss()\n",
    "    loss = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "    loss = loss.to(device)\n",
    "    x = torch.linspace(0, 1, 12800).to(device)\n",
    "    for index in torch.arange(0,len(outputs)):\n",
    "        outputY = computePoly(outputs[index],x)\n",
    "        labelsY = computePoly(labels[index],x)\n",
    "        logLoss = L2(outputY,labelsY) / 1000\n",
    "        loss = loss + logLoss\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5063e-05], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(PolynomialLossNew(torch.tensor([[10,-1,-2,0.5]], dtype=torch.float),torch.tensor([[10,-1.2,-2.3,0.6]], dtype=torch.float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,a,b,c,d):  #a is a parameter, x is the variable I want to integrate over\n",
    "    return a*x**3+b*np.power(x, 2)+ c*x+d\n",
    "\n",
    "def integral(cordinates,x):\n",
    "    print(cordinates)\n",
    "    return cordinates[0] * torch.pow(x,4).to(device) / 4   +  cordinates[1] * torch.pow(x,3).to(device) / 3 +  cordinates[2] * torch.pow(x,2).to(device) /2 +  cordinates[3] * x\n",
    "\n",
    "def integrate(cordinates,x,a,b,N):\n",
    "    fx = integral(cordinates,x)\n",
    "    area = (torch.sum(fx).to(device)) *(b-a)/N\n",
    "    return area\n",
    "def integrate1(coefficient):\n",
    "    coefficient = coefficient.numpy()\n",
    "    p = np.poly1d(coefficient) \n",
    "    p2 = np.polyint(p)\n",
    "    result = p2(1)-p2(0)\n",
    "    B = torch.from_numpy(result).float().to(device)\n",
    "    return B\n",
    "\n",
    "def integralLoss1(outputs, labels):\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        outputs - output of network ([batch size, polynomials rank + 1 (i.e., coefficients number)]) \n",
    "        labels  - desired coefficients  ([batch size, polynomials rank + 1 (i.e., coefficients number)])\n",
    "    \"\"\"\n",
    "    loss = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "    loss = loss.to(device)\n",
    "    polyList = outputs - labels\n",
    "    a = 0\n",
    "    b = 1\n",
    "    N = 1000\n",
    "    x = torch.linspace(a, b, N).to(device)\n",
    "    print(polyList)\n",
    "    for inx,poly in enumerate(polyList):\n",
    "        print(poly)\n",
    "        loss = loss + torch.abs(integralcomputaion(poly,a,b,N)).to(device)\n",
    "    \n",
    "    print('loss',loss)\n",
    "    return loss\n",
    "def integralLoss(outputs, labels):\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        outputs - output of network ([batch size, polynomials rank + 1 (i.e., coefficients number)]) \n",
    "        labels  - desired coefficients  ([batch size, polynomials rank + 1 (i.e., coefficients number)])\n",
    "    \"\"\"\n",
    "    loss = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "    loss = loss.to(device)\n",
    "    o= outputs.cpu().data.numpy()\n",
    "    l= labels.cpu().data.numpy()\n",
    "    polyList = o-l\n",
    "    for inx,poly in enumerate(polyList):\n",
    "        result = integrate.quad(f,0,1,args=(poly[0],poly[1],poly[2],poly[3]))\n",
    "        A = np.array([np.power(result[0],2)])\n",
    "        B = torch.from_numpy(A).float().to(device)\n",
    "        loss = loss + B\n",
    "                                      \n",
    "    return loss\n",
    "\n",
    "def huber_loss(outputs,labels):\n",
    "    delta = 2\n",
    "    loss = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "    loss = loss.to(device)\n",
    "    outputs= outputs.cpu().data.numpy()\n",
    "    labels= labels.cpu().data.numpy()\n",
    "    diff = labels-outputs\n",
    "    likeL2 = 0.5*((diff)**2)\n",
    "    likeL1 = delta*np.abs(diff) - 0.5*(delta**2)\n",
    "    huberLoss = np.where(np.abs(diff) < delta , likeL2, likeL1)\n",
    "    loss = loss +  torch.from_numpy(np.sum(huberLoss))\n",
    "    return loss\n",
    "def logcosh_loss(outputs,labels):\n",
    "    loss = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "    loss = loss.to(device)\n",
    "    outputs= outputs.cpu().data.numpy()\n",
    "    labels= labels.cpu().data.numpy()\n",
    "    logcoshLoss = np.log(np.cosh(outputs - labels))\n",
    "    loss = loss +  torch.from_numpy(np.sum(logcoshLoss))\n",
    "    return loss\n",
    "def L2LossWithPoints(outputs, labels):\n",
    "\n",
    "       \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        outputs - output of network ([batch size, polynomials rank + 1 (i.e., coefficients number)]) \n",
    "        labels  - desired coefficients  ([batch size, polynomials rank + 1 (i.e., coefficients number)])\n",
    "    \"\"\"\n",
    "    loss = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "    loss = loss.to(device)\n",
    "    o= outputs.cpu().data.numpy()\n",
    "    l= labels.cpu().data.numpy()\n",
    "    olist= iterateOnPoly(o)\n",
    "    llist = iterateOnPoly(l)\n",
    "    l2 =  np.linalg.norm(olist-llist)\n",
    "    loss = loss + torch.from_numpy(l2)\n",
    "                                      \n",
    "    return loss\n",
    "def iterateOnPoly(vectorPoly):\n",
    "    listOfPoint = []\n",
    "    for inx,poly in enumerate(vectorPoly):\n",
    "        points = createList(poly)\n",
    "        listOfPoint.append(points)\n",
    "    return np.array(listOfPoint)\n",
    "\n",
    "def createList(coeffs_tgt):\n",
    "    poly_tgt = np.poly1d(coeffs_tgt) # generate polynomial representation\n",
    "    x_pts = np.arange(0.0, 1.0, 0.01/128)\n",
    "    y_pts_tgt = poly_tgt(x_pts)  # execute tgt polynomial on x_pts\n",
    "    y_pts_tgt = 1 - y_pts_tgt  # b/c on screen y=0 is on top, now 0 is at bottom as we are used\n",
    "    y_pts_tgt *= 128 \n",
    "    return np.array(y_pts_tgt)\n",
    "def L2Loss(outputs, labels):\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        outputs - output of network ([batch size, polynomials rank + 1 (i.e., coefficients number)]) \n",
    "        labels  - desired coefficients  ([batch size, polynomials rank + 1 (i.e., coefficients number)])\n",
    "    \"\"\"\n",
    "    loss = torch.zeros(1, dtype=torch.float, requires_grad=True)\n",
    "    loss = loss.to(device)\n",
    "    o= outputs.cpu().data.numpy()\n",
    "    l= labels.cpu().data.numpy()\n",
    "    l2 =  np.linalg.norm(o-l)\n",
    "    A = np.array([l2])\n",
    "    B = torch.from_numpy(A).float().to(device)\n",
    "    loss = loss + B\n",
    "                                      \n",
    "    return loss\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    elif type(m)== nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "    elif type(m)== nn.BatchNorm2d:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation and choice of optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model trainable parameters: 312094\n"
     ]
    }
   ],
   "source": [
    "polyNet = PolyNet().to(device)\n",
    "polyNet.apply(init_weights)\n",
    "print (\"Number of model trainable parameters:\", get_train_params_num(polyNet))\n",
    "optimizer= torch.optim.SGD(polyNet.parameters(), lr=5, momentum=0.9,nesterov=True)\n",
    "# optimizer= torch.optim.Adam(polyNet.parameters(),lr=0.001)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.09)\n",
    "metaData = {\n",
    "    'model':polyNet,\n",
    "    'optimizer':optimizer,\n",
    "    'scheduler':exp_lr_scheduler,\n",
    "    'name':'L2LossWithPoints',\n",
    "    'loss':L2LossWithPoints\n",
    "}\n",
    "polyNet1 = PolyNet().to(device)\n",
    "polyNet1.apply(init_weights)\n",
    "optimizer1= torch.optim.SGD(polyNet1.parameters(), lr=0.01, momentum=0.9,nesterov=True)\n",
    "# optimizer1= torch.optim.Adam(polyNet1.parameters(),lr=0.001)\n",
    "\n",
    "exp_lr_scheduler1 = lr_scheduler.StepLR(optimizer1,step_size=3,gamma=0.09)\n",
    "metaData1 = {\n",
    "    'model':polyNet1,\n",
    "    'optimizer':optimizer1,\n",
    "    'scheduler':exp_lr_scheduler1,\n",
    "    'name':'L2Loss',\n",
    "    'loss':L2Loss\n",
    "}\n",
    "polyNet2 = PolyNet().to(device)\n",
    "polyNet2.apply(init_weights)\n",
    "# optimizer2= torch.optim.Adam(polyNet2.parameters(),lr=0.001)\n",
    "optimizer2=torch.optim.SGD(polyNet2.parameters(), lr=0.01, momentum=0.9,nesterov=True,weight_decay=0.00001)\n",
    "\n",
    "exp_lr_scheduler2 = lr_scheduler.StepLR(optimizer2,step_size=3,gamma=0.09)\n",
    "metaData2 = {\n",
    "    'model':polyNet2,\n",
    "    'optimizer':optimizer2,\n",
    "    'scheduler':exp_lr_scheduler2,\n",
    "    'name':'huber_loss',\n",
    "    'loss':huber_loss\n",
    "}\n",
    "polyNet3 = PolyNet().to(device)\n",
    "polyNet3.apply(init_weights)\n",
    "optimizer3= torch.optim.SGD(polyNet3.parameters(), lr=0.01, momentum=0.9,nesterov=True,weight_decay=0.00001)\n",
    "# optimizer3= torch.optim.Adam(polyNet3.parameters(),lr=0.001)\n",
    "\n",
    "polyNet4 = PolyNet().to(device)\n",
    "polyNet4.apply(init_weights)\n",
    "optimizer4= torch.optim.Adam(polyNet4.parameters(),lr=0.001)\n",
    "# optimizer4= torch.optim.SGD(polyNet4.parameters(), lr=0.01, momentum=0.9,nesterov=True)\n",
    "\n",
    "exp_lr_scheduler4 = lr_scheduler.StepLR(optimizer4,step_size=3,gamma=0.09)\n",
    "metaData4 = {\n",
    "    'model':polyNet4,\n",
    "    'optimizer':optimizer4,\n",
    "    'scheduler':exp_lr_scheduler4,\n",
    "    'name':'PolynomialLossNew',\n",
    "    'loss':PolynomialLossNew\n",
    "}\n",
    "models = []\n",
    "# models.append(metaData)\n",
    "models.append(metaData4)\n",
    "# models.append(metaData1)\n",
    "# models.append(metaData2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check rough number of ops for network (for your convenience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conv2d', (3, 3, 3, 1, 1)) : 1,327,104\n",
      "('conv2d', (3, 3, 3, 1, 1)) : 331,776\n",
      "('fc', (2883, 4)) : 11,532\n",
      "\n",
      "Total ops: 1,670,412\n"
     ]
    }
   ],
   "source": [
    "inp_size = (128,128)\n",
    "\n",
    "example_net = (('conv2d', (3, 3, 3, 1, 1)),\n",
    "               ('MaxPool2d', (2,2)),\n",
    "               ('conv2d', (3, 3, 3, 1, 1)),\n",
    "               ('MaxPool2d', (2,2)),\n",
    "               ('fc', (2883, 4)))\n",
    "\n",
    "### USE YOUR OWN NETWORK ####\n",
    "              \n",
    "ops = calc_ops(inp_size, example_net)\n",
    "print()\n",
    "print(\"Total ops: {:,}\".format(ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_noise_and_gray(images):\n",
    "    imageList = []\n",
    "    for image in images:\n",
    "        image = image.cpu().numpy()\n",
    "        image = scipy.ndimage.binary_propagation(image, mask=image)\n",
    "        image = scipy.ndimage.median_filter(image,2)\n",
    "        imageList.append(image)\n",
    "    imageList=np.array(imageList)\n",
    "    imageList = imageList.astype(float)\n",
    "    return imageList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View images, target coefficiets and  network coefficients (given to you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 128, 128])\n",
      "showing image:  ./clean_train_100//images/0000.png\n",
      "Target coeffs : [-2.56, 2.52, -0.02, 0.25]\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'handle_noise_and_gray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-57882e651b70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mimagList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_noise_and_gray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbacthes_to_show\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'handle_noise_and_gray' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "View first image of a given number of batches assuming that model has been created. Currently, code lines assuming\n",
    "model has been creatd, are commented out. Without a model, you can view target coefficients and the corresponding\n",
    "images.\n",
    "This is given to you so that you may see how loaders and model can be used. \n",
    "\"\"\"\n",
    "from skimage import color\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "loader = train_loader # choose from which loader to show images\n",
    "bacthes_to_show = 2\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(loader, 0): #0 means that counting starts at zero\n",
    "        inputs = (data['image']).to(device)\n",
    "        labels = (data['labels']).to(device)\n",
    "        print(inputs.shape)\n",
    "        img_fnames = data['fname']\n",
    "        #outputs = model(inputs.float())\n",
    "        img = Image.open(img_fnames[0])\n",
    "        \n",
    "        print (\"showing image: \", img_fnames[0])\n",
    "        \n",
    "        labels_np_arr = labels[0]   # using \".numpy()\" to convert tensor to numpy array\n",
    "        labels_str = [ float((\"{0:.2f}\".format(x))) for x in labels_np_arr]\n",
    "        \n",
    "        #outputs_np_arr = outputs[0] # using \".numpy()\" to convert tensor to numpy array\n",
    "        #outputs_str = [ float((\"{0:.2f}\".format(x))) for x in outputs_np_arr]\n",
    "        print(\"Target coeffs :\", labels_str )\n",
    "        #print(\"network coeffs:\", outputs_str)\n",
    "        print()\n",
    "        img.show()\n",
    "        imagList = handle_noise_and_gray(inputs)\n",
    "        plt.imshow(imagList[0].transpose((1, -1, 0)))\n",
    "        if (i+1) == bacthes_to_show:\n",
    "            break\n",
    "        \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate_model(model, loader):\n",
    "#     \"\"\"\n",
    "#     This function parses a given loader and returns the avergae (per image) loss (as defined by \"my_loss\" \n",
    "#     of the entire dataset associated with the given loader.\n",
    "    \n",
    "#     Args:\n",
    "#         model  - neural network to examine\n",
    "#         loader - where input data comes from (train, validation, or test)\n",
    "        \n",
    "#     returns:\n",
    "#         average loss per image in variable named \"avg_loss\"\n",
    "#     \"\"\"\n",
    "#     avg_loss = 0\n",
    "#     for i, data in enumerate(loader): #0 means that counting starts at zero\n",
    "#         image = (data['image']).to(device)\n",
    "#         labels = (data['labels']).to(device)\n",
    "#         # Forward pass\n",
    "#         outputs = model(image.float())\n",
    "#         loss = my_loss(outputs, labels)\n",
    "#         avg_loss = avg_loss + loss\n",
    "        \n",
    "#     avg_loss = avg_loss / (len(loader)*loader.batch_size)\n",
    "#     return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch for model: PolynomialLossNew 0/299\n",
      "tensor([0.0026], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 1/299\n",
      "tensor([0.0012], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 2/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 3/299\n",
      "tensor([0.0014], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 4/299\n",
      "tensor([0.0007], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 5/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 6/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 7/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 8/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 9/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 10/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 11/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 12/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 13/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 14/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 15/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 16/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 17/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 18/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 19/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 20/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 21/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 22/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 23/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 24/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 25/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 26/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 27/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 28/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 29/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 30/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 31/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 32/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 33/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 34/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 35/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 36/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 37/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 38/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 39/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 40/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 41/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 42/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 43/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 44/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 45/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 46/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 47/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 48/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 49/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 50/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 51/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 52/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 53/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 54/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 55/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 56/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 57/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 58/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 59/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 60/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 61/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 62/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 63/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 64/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 65/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 66/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 67/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 68/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 69/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 70/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 71/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 72/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 73/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 74/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 75/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 76/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 77/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 78/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 79/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 80/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 81/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 82/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch for model: PolynomialLossNew 83/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 84/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 85/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 86/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 87/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 88/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 89/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 90/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 91/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 92/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 93/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 94/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 95/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 96/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 97/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 98/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 99/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 100/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 101/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 102/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 103/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 104/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 105/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 106/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 107/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 108/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 109/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 110/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 111/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 112/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 113/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 114/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 115/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 116/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 117/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 118/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 119/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 120/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 121/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 122/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 123/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 124/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 125/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 126/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 127/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 128/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 129/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 130/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 131/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 132/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 133/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 134/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 135/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 136/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 137/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 138/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 139/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 140/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 141/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 142/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 143/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 144/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 145/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 146/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 147/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 148/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 149/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 150/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 151/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 152/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 153/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 154/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 155/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 156/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 157/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 158/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 159/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 160/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 161/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 162/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 163/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 164/299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 165/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 166/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 167/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 168/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 169/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 170/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 171/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 172/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 173/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 174/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 175/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 176/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 177/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 178/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 179/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 180/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 181/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 182/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 183/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 184/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 185/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 186/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 187/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 188/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 189/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 190/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 191/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 192/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 193/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 194/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 195/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 196/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 197/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 198/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 199/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 200/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 201/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 202/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 203/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 204/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 205/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 206/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 207/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 208/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 209/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 210/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 211/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 212/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 213/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 214/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 215/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 216/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 217/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 218/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 219/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 220/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 221/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 222/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 223/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 224/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 225/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 226/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 227/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 228/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 229/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 230/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 231/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 232/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 233/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 234/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 235/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 236/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 237/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 238/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 239/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 240/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 241/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 242/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 243/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 244/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 245/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 246/299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 247/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 248/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 249/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 250/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 251/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 252/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 253/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 254/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 255/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 256/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 257/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 258/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 259/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 260/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 261/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 262/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 263/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 264/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 265/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 266/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 267/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 268/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 269/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 270/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 271/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 272/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 273/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 274/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 275/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 276/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 277/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 278/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 279/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 280/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 281/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 282/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 283/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 284/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 285/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 286/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 287/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 288/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 289/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 290/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 291/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 292/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 293/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 294/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 295/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 296/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 297/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 298/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch for model: PolynomialLossNew 299/299\n",
      "tensor([0.0006], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def phase_train(model,optimizer,scheduler,train_loader,train_losses,my_loss):\n",
    "    scheduler.step()\n",
    "    model.train()  #back to default\n",
    "    avg_loss = 0\n",
    "    for i, data in enumerate(train_loader): #0 means that counting starts at zero\n",
    "            image = (data['image']).to(device)\n",
    "            labels = (data['labels']).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(image.float())\n",
    "            loss = my_loss(outputs, labels)\n",
    "            avg_loss = avg_loss + loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    avg_loss = avg_loss / (len(train_loader)*train_loader.batch_size) \n",
    "    print(avg_loss)\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    return model,optimizer,scheduler\n",
    "\n",
    "def phase_validation(model,optimizer,scheduler,validation_loader,validation_losses,best_model_wts,best_loss,my_loss):\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    avg_val_loss = 0\n",
    "    for i, data in enumerate(validation_loader): #0 means that counting starts at zero\n",
    "        image = (data['image']).to(device)\n",
    "        labels = (data['labels']).to(device)\n",
    "#         image1 = handle_noise_and_gray(image)\n",
    "#         image1 = torch.from_numpy(image1)\n",
    "#         image1 = image1.to(device,dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():    \n",
    "            outputs = model(image.float())\n",
    "            loss = my_loss(outputs, labels)\n",
    "            avg_val_loss = avg_val_loss + loss\n",
    " \n",
    "    avg_val_loss = avg_val_loss / (len(validation_loader)*validation_loader.batch_size)   \n",
    "    validation_losses.append(avg_val_loss)\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        best_model_wts=copy.deepcopy(model.state_dict())\n",
    " \n",
    "    return best_model_wts,best_loss,model,optimizer,scheduler\n",
    "\n",
    "def train_model(model,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                train_loader,\n",
    "                validation_loader,\n",
    "                train_losses,\n",
    "                validation_losses,\n",
    "                name,\n",
    "                my_loss,\n",
    "                epochs=1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Trains a neural network. \n",
    "    Args;\n",
    "        model               - model to be trained\n",
    "        optimizer           - optimizer used for training\n",
    "        train_loader        - loader from which data for training comes \n",
    "        validation_loader   - loader from which data for validation comes (maybe at the end, you use test_loader)\n",
    "        train_losses        - adding train loss value after each epoch to this list for future analysis\n",
    "        validation_losses   - adding validation loss value after each epoch to this list for future analysis\n",
    "        epochs              - number of runs over the entire data set \n",
    "        \n",
    "    No value is returned - model is updated during training \n",
    "    \n",
    "    \"\"\"\n",
    "    best_loss = 10000000000.0\n",
    "    best_model_wts=copy.deepcopy(model.state_dict())    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch for model: {} {}/{}'.format(name,epoch,epochs-1))\n",
    "        model,optimizer,scheduler = phase_train(model,optimizer,scheduler,train_loader,train_losses,my_loss)\n",
    "        best_model_wts,best_loss,model,optimizer,scheduler = phase_validation(model,optimizer,scheduler,validation_loader,validation_losses,best_model_wts,best_loss,my_loss)\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return {'model':model,'train_losses':train_losses,'validation_losses':validation_losses,'id':'{}={}'.format(name, uuid.uuid4())}\n",
    "\n",
    "\n",
    "if not 'train_losses' in vars():\n",
    "    train_losses = []\n",
    "if not 'validation_losses' in vars():\n",
    "    validation_losses = []\n",
    "\n",
    "results = []\n",
    "for metaData in models:\n",
    "    result = train_model(metaData['model'], \n",
    "                metaData['optimizer'],\n",
    "                metaData['scheduler'],\n",
    "                train_loader, \n",
    "                validation_loader, \n",
    "                [], \n",
    "                [],\n",
    "                metaData['name'],\n",
    "                metaData['loss'],         \n",
    "                epochs=300)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual train (given to you)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot losses from training process (given to you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "for result in results:    \n",
    "    iteration = np.arange(0., len(result['train_losses']))\n",
    "    plt.plot(iteration, result['train_losses'], 'g-')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/Load Model (given to you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, train_losses, validation_losses, save_dir):\n",
    "    \"\"\"\n",
    "    saving model, train losses, and validation losses\n",
    "    Args:\n",
    "        model              - NN to be saved\n",
    "        train_losses       - history of losses for training dataset\n",
    "        validation_losses  - history of losses for validation dataset\n",
    "        save_dir           - directory where to save the above\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    torch.save(model, save_dir + \"/model.dat\")\n",
    "    \n",
    "    train_losses_f = open(save_dir + \"/train_losses.txt\", \"wt\")\n",
    "    train_losses_f.writelines( \"%.3f\\n\" % item for item in train_losses)\n",
    "    \n",
    "    validation_losses_f = open(save_dir + \"/validation_losses.txt\", \"wt\")\n",
    "    validation_losses_f.writelines( \"%.3f\\n\" % item for item in validation_losses)\n",
    "\n",
    "    return\n",
    "   \n",
    "\n",
    "def load(save_dir):\n",
    "    \"\"\"\n",
    "    loading model, train losses, and validation losses\n",
    "    Args:\n",
    "       save_dir  - dir name from where to load \n",
    "    \"\"\"\n",
    "    \n",
    "    model = torch.load(save_dir + \"/model.dat\") \n",
    "    \n",
    "    train_losses_f = open(save_dir + \"/train_losses.txt\", \"rt\")\n",
    "    train_losses    = train_losses_f.readlines()\n",
    "    train_losses   = [float(num) for num in train_losses]\n",
    "    \n",
    "    validation_losses_f = open(save_dir + \"/validation_losses.txt\", \"rt\")\n",
    "    validation_losses   = validation_losses_f.readlines()\n",
    "    validation_losses   = [float(num) for num in validation_losses]\n",
    "    \n",
    "    return (model, train_losses, validation_losses)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type PolyNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Create a directory \"./saves/\" where you place your saved models\n",
    "\n",
    "save(model, train_losses, validation_losses, \"./saves/try/\")\n",
    "\n",
    "model, train_losses, validation_losses = load(\"./saves/try/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw target and net polynomials (given to you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_points_dict_for_all_images(model, loader): \n",
    "    \"\"\"\n",
    "    create a dictionary of dictionaries, where main key is file name of image.\n",
    "    Each elemnts is then a dictionary of two items: 'pts_net', 'pts_tgt'\n",
    "    each such item is a list of points of the form: [[x1,y1], [x2,y2],....]\n",
    "    \n",
    "    Args:\n",
    "        model     - network for which polynimials are examined\n",
    "        loader    - input data to use \n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "                  # (dropout is set to zero)\n",
    "\n",
    "    points_dict = {}  \n",
    "        \n",
    "    k=0\n",
    "    print (\"generating points_dict for all images:\")\n",
    "    \n",
    "    for data in loader:\n",
    "        # get inputs\n",
    "        inputs = (data['image']).to(device)\n",
    "        labels = (data['labels']).to(device)\n",
    "        img_fnames = data['fname'] \n",
    "      \n",
    "        \n",
    "        # forward\n",
    "        outputs = model(inputs.float())\n",
    "        curr_batch_size = np.shape(outputs)[0]\n",
    "        print(curr_batch_size)\n",
    "        coeffs_num = np.shape(labels)[1]  # labels shape is (batch_size, coeffs_num)\n",
    "        image_size = np.shape(inputs[0])  # image_size = [3, w, h]\n",
    "        _, width, height = image_size\n",
    "        \n",
    "        for i in range (curr_batch_size): \n",
    "            coeffs_net = [] \n",
    "            coeffs_tgt = []\n",
    "            for curr_coeff in range(coeffs_num):\n",
    "                coeffs_net.append(outputs[i, curr_coeff].item()) \n",
    "                coeffs_tgt.append(labels[i, curr_coeff].item())\n",
    "                \n",
    "\n",
    "            poly_net = np.poly1d(coeffs_net) # generate polynomial representation\n",
    "            poly_tgt = np.poly1d(coeffs_tgt) # generate polynomial representation\n",
    "\n",
    "    \n",
    "            x_pts = np.arange(0.0, 1.0, 0.01/width)\n",
    "            y_pts_net = poly_net(x_pts)  # execute net polynomial on x_pts\n",
    "            y_pts_tgt = poly_tgt(x_pts)  # execute tgt polynomial on x_pts\n",
    "            \n",
    "            y_pts_net = 1 - y_pts_net  # b/c on screen y=0 is on top, now 0 is at bottom as we are used\n",
    "            y_pts_tgt = 1 - y_pts_tgt  # b/c on screen y=0 is on top, now 0 is at bottom as we are used\n",
    "    \n",
    "            x_pts *= width\n",
    "            y_pts_net *= height\n",
    "            y_pts_tgt *= height\n",
    "    \n",
    "            \n",
    "            pts_net = [list(a) for a in  zip(x_pts, y_pts_net)]\n",
    "            pts_tgt = [list(a) for a in  zip(x_pts, y_pts_tgt)]\n",
    "\n",
    "            input_fname = img_fnames[i] \n",
    "            k+=1\n",
    "            print (str(k) + \".   \" + input_fname)\n",
    "            points_dict[input_fname] = {'pts_net': pts_net,\n",
    "                                        'pts_tgt': pts_tgt} \n",
    "   \n",
    "    model.train()  #back to default           \n",
    "    return points_dict\n",
    "\n",
    "\n",
    "def draw_poly(points_dict, out_dir):\n",
    "    \"\"\"\n",
    "    Draws polynomials from given dictionary of dictionaries \n",
    "    \n",
    "    Args:\n",
    "        points_dict - dictionary. key is file name of frame (fname) and elemet is a dictionary with\n",
    "                       keys: 'pts_net', 'pts_tgt'. Each of which has a list of points:(x,y)\n",
    "        out_dir     - ouptut directory name (e.g.: 'draws/')\n",
    "    \"\"\"\n",
    "    \n",
    "       \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    files = glob.glob(out_dir + '*.png')\n",
    "    for f in files:\n",
    "        os.remove(f) \n",
    "\n",
    "\n",
    "    print(\"Marking frames:\")\n",
    "    index = 1\n",
    "    for fname in points_dict:\n",
    "        orig_img = Image.open(fname)\n",
    "        img = Image.new(orig_img.mode, orig_img.size, (255, 255, 255))\n",
    "        \n",
    "        fname_points_list_net = points_dict[fname]['pts_net']\n",
    "        fname_points_list_tgt = points_dict[fname]['pts_tgt']\n",
    "\n",
    "        fname_points_list_net = [(point[0], point[1]) for point in fname_points_list_net]\n",
    "        fname_points_list_tgt = [(point[0], point[1]) for point in fname_points_list_tgt]\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.point(fname_points_list_net, (255, 0, 0, 255))  # net: red\n",
    "        draw.point(fname_points_list_tgt, (0, 255, 0, 255))  # tgt: green\n",
    "        \n",
    "    \n",
    "        img.save(out_dir + fname.split('/')[-1])\n",
    "        \n",
    "        print (index, out_dir + fname.split('/')[-1])\n",
    "        index+=1\n",
    "        \n",
    "        \n",
    "def draw_loader_polynomials(model, loader, out_dir):\n",
    "    \"\"\"\n",
    "    This fucntion receives a model and a loader and for each polymonial image in the loader it draws\n",
    "    the polynomial that it identifies. Both polynomials (the original (in green) and the network's (in red)) \n",
    "    are saved as an image in the given out_dir diretory.\n",
    "    Args:\n",
    "        model   - network for which polynimials are drawn\n",
    "        loader  - input data to use \n",
    "        out_dir - ouptut directory name (e.g.: 'draws/')   \n",
    "    \"\"\"\n",
    "    \n",
    "    points_dict = gen_points_dict_for_all_images(model, loader)  \n",
    "    draw_poly(points_dict, out_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_only_base_image(loader): \n",
    "    points_dict = {}   \n",
    "    k=0  \n",
    "    for data in loader:\n",
    "\n",
    "        inputs = (data['image']).to(device)\n",
    "        labels = (data['labels']).to(device)\n",
    "        img_fnames = data['fname'] \n",
    "        coeffs_num = np.shape(labels)[1]  # labels shape is (batch_size, coeffs_num)\n",
    "        image_size = [3,128,128]  # image_size = [3, w, h]\n",
    "        curr_batch_size = labels.shape[0]\n",
    "        _, width, height = image_size\n",
    "        for i in range (curr_batch_size): \n",
    "            coeffs_tgt = []\n",
    "            for curr_coeff in range(coeffs_num):\n",
    "                coeffs_tgt.append(labels[i, curr_coeff].item())\n",
    "            poly_tgt = np.poly1d(coeffs_tgt) # generate polynomial representation\n",
    "            x_pts = np.arange(0.0, 1.0, 0.01/width)\n",
    "            y_pts_tgt = poly_tgt(x_pts)  # execute tgt polynomial on x_pts\n",
    "            y_pts_tgt = 1 - y_pts_tgt  # b/c on screen y=0 is on top, now 0 is at bottom as we are used\n",
    "            x_pts *= width\n",
    "            y_pts_tgt *= height            \n",
    "            pts_tgt = [list(a) for a in  zip(x_pts, y_pts_tgt)]\n",
    "            \n",
    "            input_fname = img_fnames[i] \n",
    "            k+=1\n",
    "            points_dict[input_fname] = {'pts_tgt': pts_tgt} \n",
    "\n",
    "    return points_dict\n",
    "\n",
    " \n",
    "def draw_poly_clean(points_dict, out_dir):\n",
    "     \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    files = glob.glob(out_dir + '*.png')\n",
    "    for f in files:\n",
    "        os.remove(f) \n",
    "    index = 1\n",
    "    for fname in points_dict:\n",
    "        orig_img = Image.open(fname)\n",
    "        img = Image.new(orig_img.mode, orig_img.size, (255, 255, 255))\n",
    "        fname_points_list_tgt = points_dict[fname]['pts_tgt']\n",
    "        fname_points_list_tgt = [(point[0], point[1]) for point in fname_points_list_tgt]\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.point(fname_points_list_tgt, (0, 0, 0, 0))  # tgt: green\n",
    "        img.save(out_dir + fname.split('/')[-1])   \n",
    "        index+=1\n",
    "        \n",
    "        \n",
    "def draw_clean_polynomials(loader, out_dir):\n",
    "    \"\"\"\n",
    "    This fucntion receives a model and a loader and for each polymonial image in the loader it draws\n",
    "    the polynomial that it identifies. Both polynomials (the original (in green) and the network's (in red)) \n",
    "    are saved as an image in the given out_dir diretory.\n",
    "    Args:\n",
    "        model   - network for which polynimials are drawn\n",
    "        loader  - input data to use \n",
    "        out_dir - ouptut directory name (e.g.: 'draws/')   \n",
    "    \"\"\"\n",
    "    \n",
    "    points_dict = get_only_base_image(loader)  \n",
    "    draw_poly_clean(points_dict, out_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'draw_clean_polynomials' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-0dc3399016b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdraw_clean_polynomials\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./validation/clean_validation/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'draw_clean_polynomials' is not defined"
     ]
    }
   ],
   "source": [
    "draw_clean_polynomials( validation_loader, './validation/clean_validation/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Example of how to draw target and net polynomials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating points_dict for all images:\n",
      "1\n",
      "1.   ./clean_train_10//images/0000.png\n",
      "1\n",
      "2.   ./clean_train_10//images/0001.png\n",
      "1\n",
      "3.   ./clean_train_10//images/0002.png\n",
      "1\n",
      "4.   ./clean_train_10//images/0003.png\n",
      "1\n",
      "5.   ./clean_train_10//images/0004.png\n",
      "1\n",
      "6.   ./clean_train_10//images/0005.png\n",
      "1\n",
      "7.   ./clean_train_10//images/0006.png\n",
      "1\n",
      "8.   ./clean_train_10//images/0007.png\n",
      "1\n",
      "9.   ./clean_train_10//images/0008.png\n",
      "1\n",
      "10.   ./clean_train_10//images/0009.png\n",
      "Marking frames:\n",
      "1 ./validation/draw/PolynomialLossNew=a2e4835e-0765-42ad-ada1-8071334f5ddf/0000.png\n",
      "2 ./validation/draw/PolynomialLossNew=a2e4835e-0765-42ad-ada1-8071334f5ddf/0001.png\n",
      "3 ./validation/draw/PolynomialLossNew=a2e4835e-0765-42ad-ada1-8071334f5ddf/0002.png\n",
      "4 ./validation/draw/PolynomialLossNew=a2e4835e-0765-42ad-ada1-8071334f5ddf/0003.png\n",
      "5 ./validation/draw/PolynomialLossNew=a2e4835e-0765-42ad-ada1-8071334f5ddf/0004.png\n",
      "6 ./validation/draw/PolynomialLossNew=a2e4835e-0765-42ad-ada1-8071334f5ddf/0005.png\n",
      "7 ./validation/draw/PolynomialLossNew=a2e4835e-0765-42ad-ada1-8071334f5ddf/0006.png\n",
      "8 ./validation/draw/PolynomialLossNew=a2e4835e-0765-42ad-ada1-8071334f5ddf/0007.png\n",
      "9 ./validation/draw/PolynomialLossNew=a2e4835e-0765-42ad-ada1-8071334f5ddf/0008.png\n",
      "10 ./validation/draw/PolynomialLossNew=a2e4835e-0765-42ad-ada1-8071334f5ddf/0009.png\n"
     ]
    }
   ],
   "source": [
    "# Drawing polynomials from validation loader and placing them in directory \"./validation/draw/\"\n",
    "# The green colored polynomials are the desired outputs and the red polynomials are network's \n",
    "# actual outputs. Notice that if in an image you see no red polynomial, it means it is not inside the \n",
    "# [0,1]x[0,1] \"box\", which is the domain considered.  This means that your model has siginificant error\n",
    "\n",
    "for result in results:   \n",
    "    draw_loader_polynomials(result['model'], validation_loader, './validation/draw/{}/'.format(result['id']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
