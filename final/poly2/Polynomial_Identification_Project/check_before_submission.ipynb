{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing your model works before submisson\n",
    "\n",
    "In order to make sure that your model will work when tested, you should run this notebook. Take the following steps:\n",
    "1. Have your model.dat file placed in a directory of your choosing. \n",
    "2. Paste the code of your PolyNet class in the second to last cell of this notebook. ** Make sure your PolyNet class code matches the code used to generate model.dat!**\n",
    "3. In the last cell, make sure to load your model from the right directory\n",
    "4. Run the this whole notebook. Then verify that target polynomials and network's polynomials are drawn in files located at \"./test/draw\" directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_dir):\n",
    "        \"\"\"\n",
    "        Initializing dataset by generating a dicitonary of labels, where an image file name is the key \n",
    "        and its labels are the contents of that entry in the dictionary. Images are not loaded. This way it\n",
    "        is possible to iterate over arbitrarily large datasets (limited by labels dicitonary fitting \n",
    "        in memory, which is not a problem in practice)\n",
    "        \n",
    "        Args:\n",
    "            dataset_dir : path to directory with images and labels. In this directory we expect to find\n",
    "                          a directory called \"images\" containing the input images, and a file called \n",
    "                          \"labels.txt\" containing desired labels (coefficients)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.labels_dict = self.gen_labels_dict()\n",
    "        self.images_keys = list(self.labels_dict)  # getting the keys of the dictionary as list\n",
    "        self.images_keys.sort()                    # sorting so as to have in alphabetical order \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_dict)\n",
    "\n",
    "    def __getitem__(self, index):    \n",
    "        \"\"\"\n",
    "        This funtion makes it possible to iterate over the PolyDataset\n",
    "        Args:\n",
    "            index: running index of images\n",
    "            \n",
    "        Returns:\n",
    "            sample: a dicitionary with three entries:\n",
    "                    1. 'image'  contains the image\n",
    "                    2. 'labels' contains labels (coeffs) corresponding to image\n",
    "                    3. 'fname'  contains name of file (image_key) - may be useful for debugging\n",
    "        \"\"\"\n",
    "        image_key = self.images_keys[index]     # recall - key is the file name of the corresponding image\n",
    "        image = np.array(Image.open(image_key)) # image has shape: (128, 128, 3)\n",
    "        image = image/255.0                     # simple normalization - just to maintain small numbers\n",
    "        image = np.transpose(image, (2, 0, 1))  # network needs RGB channels to be first index\n",
    "        labels = self.labels_dict[image_key]\n",
    "        sample = {'image': image, 'labels': labels, 'fname':image_key}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    def gen_labels_dict(self):\n",
    "        \"\"\"\n",
    "        This fucntion generates a dictionary of labels\n",
    "        \n",
    "        Returns:\n",
    "            labels_dict: the key is image file name and an array of labels is the corresponding contents \n",
    "        \"\"\"\n",
    "        \n",
    "        labels_fname = self.dataset_dir + \"/labels.txt\"\n",
    "        labels_dict = {}\n",
    "        with open(labels_fname, \"r\") as inp:\n",
    "            for line in inp:\n",
    "                line = line.split('\\n')[0]                                      # remove '\\n' from end of line \n",
    "                line = line.split(',')\n",
    "                key  = self.dataset_dir + '/images/' + line[0].strip() + \".png\" # image file name is the key\n",
    "                del line[0]\n",
    "                \n",
    "                list_from_line = [float(item) for item in line]\n",
    "                labels_dict[key] = np.asarray(list_from_line, dtype=np.float32)\n",
    "                        \n",
    "        return labels_dict             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dir = \"./test/\"  \n",
    "\n",
    "\n",
    "test_dataset = PolyDataset(test_dir)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size=1,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_points_dict_for_all_images(model, loader): \n",
    "    \"\"\"\n",
    "    create a dictionary of dictionaries, where main key is file name of image.\n",
    "    Each elemnts is then a dictionary of two items: 'pts_net', 'pts_tgt'\n",
    "    each such item is a list of points of the form: [[x1,y1], [x2,y2],....]\n",
    "    \n",
    "    Args:\n",
    "        model     - network for which polynimials are examined\n",
    "        loader    - input data to use \n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "                  # (dropout is set to zero)\n",
    "    \n",
    "    points_dict = {}  \n",
    "        \n",
    "    k=0\n",
    "    print (\"generating points_dict for all images:\")\n",
    "    \n",
    "    for data in loader:\n",
    "        # get inputs\n",
    "        inputs = (data['image']).to(device)\n",
    "        labels = (data['labels']).to(device)\n",
    "        img_fnames = data['fname'] \n",
    "      \n",
    "        \n",
    "        # forward\n",
    "        outputs = model(inputs.float())\n",
    "        curr_batch_size = np.shape(outputs)[0]\n",
    "        coeffs_num = np.shape(labels)[1]  # labels shape is (batch_size, coeffs_num)\n",
    "        image_size = np.shape(inputs[0])  # image_size = [3, w, h]\n",
    "        _, width, height = image_size\n",
    "        \n",
    "        for i in range (curr_batch_size): \n",
    "            coeffs_net = [] \n",
    "            coeffs_tgt = []\n",
    "            for curr_coeff in range(coeffs_num):\n",
    "                coeffs_net.append(outputs[i, curr_coeff].item()) \n",
    "                coeffs_tgt.append(labels[i, curr_coeff].item())\n",
    "                \n",
    "\n",
    "            poly_net = np.poly1d(coeffs_net) # generate polynomial representation\n",
    "            poly_tgt = np.poly1d(coeffs_tgt) # generate polynomial representation\n",
    "\n",
    "    \n",
    "            x_pts = np.arange(0.0, 1.0, 0.01/width)\n",
    "            y_pts_net = poly_net(x_pts)  # execute net polynomial on x_pts\n",
    "            y_pts_tgt = poly_tgt(x_pts)  # execute tgt polynomial on x_pts\n",
    "            \n",
    "            y_pts_net = 1 - y_pts_net  # b/c on screen y=0 is on top, now 0 is at bottom as we are used\n",
    "            y_pts_tgt = 1 - y_pts_tgt  # b/c on screen y=0 is on top, now 0 is at bottom as we are used\n",
    "    \n",
    "            x_pts *= width\n",
    "            y_pts_net *= height\n",
    "            y_pts_tgt *= height\n",
    "    \n",
    "            \n",
    "            pts_net = [list(a) for a in  zip(x_pts, y_pts_net)]\n",
    "            pts_tgt = [list(a) for a in  zip(x_pts, y_pts_tgt)]\n",
    "\n",
    "            input_fname = img_fnames[i] \n",
    "            k+=1\n",
    "            print (str(k) + \".   \" + input_fname)\n",
    "            points_dict[input_fname] = {'pts_net': pts_net,\n",
    "                                        'pts_tgt': pts_tgt} \n",
    "            \n",
    "    return points_dict\n",
    "\n",
    "\n",
    "def draw_poly(points_dict, out_dir):\n",
    "    \"\"\"\n",
    "    Draws polynomials from given dictionary of dictionaries \n",
    "    \n",
    "    Args:\n",
    "        points_dict - dictionary. key is file name of frame (fname) and elemet is a dictionary with\n",
    "                       keys: 'pts_net', 'pts_tgt'. Each of which has a list of points:(x,y)\n",
    "        out_dir     - ouptut directory name (e.g.: 'draws/')\n",
    "    \"\"\"\n",
    "    \n",
    "       \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    files = glob.glob(out_dir + '*.png')\n",
    "    for f in files:\n",
    "        os.remove(f) \n",
    "\n",
    "\n",
    "    print(\"Marking frames:\")\n",
    "    index = 1\n",
    "    for fname in points_dict:\n",
    "        orig_img = Image.open(fname)\n",
    "        img = Image.new(orig_img.mode, orig_img.size, (255, 255, 255))\n",
    "        \n",
    "        fname_points_list_net = points_dict[fname]['pts_net']\n",
    "        fname_points_list_tgt = points_dict[fname]['pts_tgt']\n",
    "\n",
    "        fname_points_list_net = [(point[0], point[1]) for point in fname_points_list_net]\n",
    "        fname_points_list_tgt = [(point[0], point[1]) for point in fname_points_list_tgt]\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.point(fname_points_list_net, (255, 0, 0, 255))  # net: red\n",
    "        draw.point(fname_points_list_tgt, (0, 255, 0, 255))  # tgt: green\n",
    "        \n",
    "    \n",
    "        img.save(out_dir + fname.split('/')[-1])\n",
    "        \n",
    "        print (index, out_dir + fname.split('/')[-1])\n",
    "        index+=1\n",
    "        \n",
    "        \n",
    "def draw_loader_polynomials(model, loader, out_dir):\n",
    "    \"\"\"\n",
    "    This fucntion receives a model and a loader and for each polymonial image in the loader it draws\n",
    "    the polynomial that it identifies. Both polynomials (the original (in green) and the network's (in red)) \n",
    "    are saved as an image in the given out_dir diretory.\n",
    "    Args:\n",
    "        model   - network for which polynimials are drawn\n",
    "        loader  - input data to use \n",
    "        out_dir - ouptut directory name (e.g.: 'draws/')   \n",
    "    \"\"\"\n",
    "    \n",
    "    points_dict = gen_points_dict_for_all_images(model, loader)  \n",
    "    draw_poly(points_dict, out_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeparableConv2d(nn.Module):  #In case it is used\n",
    "    \"\"\"\n",
    "    Seperable convolution - you can try it out if you want\n",
    "    \"\"\"\n",
    "    def __init__(self,in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super(SeparableConv2d,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels,\n",
    "                               in_channels,\n",
    "                               kernel_size,\n",
    "                               stride,\n",
    "                               padding,\n",
    "                               dilation,\n",
    "                               groups=in_channels,\n",
    "                               bias=bias)\n",
    "        \n",
    "        self.pointwise = nn.Conv2d(in_channels, \n",
    "                                   out_channels, \n",
    "                                   kernel_size=1,\n",
    "                                   stride=1, \n",
    "                                   padding=0, \n",
    "                                   dilation=1, \n",
    "                                   groups=1, \n",
    "                                   bias=bias)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your model definition is needed here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolyNet(nn.Module):      \n",
    "    \"\"\"\n",
    "    You must place your model class definition here in order for \"torch.load\" below to work\n",
    "    \"\"\"\n",
    "             \n",
    " \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"./saves/model.dat\")  # make sure you place here the path to your model\n",
    "\n",
    "draw_loader_polynomials(model, test_loader, './test/draw/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
